# -*- coding: utf-8 -*-
"""RagChatbotColab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13S-wocVKqijn5Pg9VxQ3OdId6-A1wgSQ
"""

!pip install -q google-genai sentence-transformers faiss-cpu PyPDF2

import os
from getpass import getpass

# Gemini API anahtarÄ± gir
gemini_key = getpass("Gemini API key (Google AI Studio'dan aldÄ±ÄŸÄ±n): ")
if gemini_key:
    os.environ["GEMINI_API_KEY"] = gemini_key

# HuggingFace token gir
hf_key = getpass("HuggingFace token (https://huggingface.co/settings/tokens): ")
if hf_key:
    os.environ["HF_TOKEN"] = hf_key

print("ğŸ”‘ API anahtarlarÄ± ayarlandÄ± (gizli).")

!mkdir -p /content/docs
!wget -q -O /content/docs/is_kanunu.pdf "https://cdn.istanbul.edu.tr/FileHandler2.ashx?f=is-kanunu-%284857%29.pdf"

import PyPDF2

def read_text_from_file(path):
    text = ""
    if path.endswith(".pdf"):
        with open(path, "rb") as f:
            reader = PyPDF2.PdfReader(f)
            for page in reader.pages:
                text += page.extract_text() or ""
    else:
        with open(path, "r", encoding="utf-8") as f:
            text = f.read()
    return text

doc_text = read_text_from_file("/content/docs/is_kanunu.pdf")
print(doc_text[:500])  # ilk 500 karakter

def chunk_text(text, max_len=500):
    words = text.split()
    chunks, current = [], []
    for w in words:
        current.append(w)
        if len(current) >= max_len:
            chunks.append(" ".join(current))
            current = []
    if current:
        chunks.append(" ".join(current))
    return chunks

chunks = chunk_text(doc_text, max_len=300)
print("Toplam parÃ§a:", len(chunks))
print(chunks[0][:200])  # ilk chunk

from sentence_transformers import SentenceTransformer

EMB_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
embedder = SentenceTransformer(EMB_MODEL)

X = embedder.encode(chunks, batch_size=32, show_progress_bar=True, convert_to_numpy=True, normalize_embeddings=True)

import faiss
import pickle

d = X.shape[1]
index = faiss.IndexFlatIP(d)
index.add(X)

faiss.write_index(index, "/content/faiss.index")
with open("/content/chunks.pkl", "wb") as f:
    pickle.dump(chunks, f)

print("ğŸ“¦ FAISS index oluÅŸturuldu. VektÃ¶r sayÄ±sÄ±:", index.ntotal)

def search(query, k=3):
    qv = embedder.encode([query], convert_to_numpy=True, normalize_embeddings=True)
    D, I = index.search(qv, k)
    return [(chunks[i], float(D[0][j])) for j, i in enumerate(I[0])]

print(search("iÅŸÃ§i haklarÄ± nelerdir?", 2))

from google import genai

client = genai.Client(api_key=os.environ["GEMINI_API_KEY"])

def rag_chat(query, k=3):
    # ilgili parÃ§alarÄ± getir
    results = search(query, k)
    context = "\n\n".join([r[0] for r in results])

    prompt = f"""
Sen bir yardÄ±mcÄ± chatbot'sun.
KullanÄ±cÄ±nÄ±n sorusunu yanÄ±tlamak iÃ§in aÅŸaÄŸÄ±daki baÄŸlamÄ± kullan:
---
{context}
---
Soru: {query}
Cevap:
    """

    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt
    )
    return response.text

print(rag_chat("Fazla mesai nasÄ±l hesaplanÄ±r?"))

import gradio as gr

# RAG Chat fonksiyonu
def rag_chat_with_history(query, chat_history):
    """
    chat_history: Ã¶nceki (soru, cevap) listesi
    """
    # En iyi 3 parÃ§ayÄ± getir (proje iÃ§in uygun k=3)
    k = 3
    results = search(query, k)
    context = "\n\n".join([r[0] for r in results])

    prompt = f"""
Sen bir yardÄ±mcÄ± chatbot'sun.
KullanÄ±cÄ±nÄ±n sorusunu yanÄ±tlamak iÃ§in aÅŸaÄŸÄ±daki baÄŸlamÄ± kullan:
---
{context}
---
Soru: {query}
Cevap:
    """

    # Gemini API Ã§aÄŸrÄ±sÄ±
    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt
    ).text

    # chat_history gÃ¼ncelle
    chat_history = chat_history or []
    chat_history.append((query, response))
    return chat_history, chat_history

with gr.Blocks() as demo:
    gr.Markdown("## ğŸŸ¢ Åirket Ä°Ã§i Bilgi BankasÄ± Chatbot")

    chatbot = gr.Chatbot(label="Chatbot")
    user_input = gr.Textbox(label="Soru", placeholder="Sorunuzu yazÄ±n...")
    clear_btn = gr.Button("Temizle")

    # input gÃ¶nderildiÄŸinde chat fonksiyonu Ã§alÄ±ÅŸsÄ±n
    user_input.submit(
        rag_chat_with_history,
        inputs=[user_input, chatbot],
        outputs=[chatbot, chatbot]
    )

    clear_btn.click(lambda: [], None, chatbot)

demo.launch()